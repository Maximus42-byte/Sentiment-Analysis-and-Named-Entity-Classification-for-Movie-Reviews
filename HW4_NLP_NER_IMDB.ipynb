{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<div dir = \"rtl\" style = 'font-family: \"B Zar\";' align = \"center\">\n",
        "    <h1 align = \"center\">\n",
        "        به نام خدا\n",
        "    </h1>\n",
        "    <h3 align = \"center\">\n",
        "        تمرین چهارم پردازش زبان - تشخیص موجودیت های نامدار مدل برت\n",
        "    </h3>\n",
        "    <h3 align = \"center\">\n",
        "        استاد: دکتر عسگری\n",
        "    </h3>\n",
        "    <h3 align = \"center\">\n",
        "         محمدرضا کمالی -      \n",
        "         مهدی سعیدی  \n",
        "    </h3>\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "i-OpNik6R0sR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries and Tools"
      ],
      "metadata": {
        "id": "ISB-MUZPBUOs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<div dir = \"rtl\" style = 'font-family: \"B Zar\";'>\n",
        "\n",
        "  <p>\n",
        "کتابخانه ها و ابزار های مورد نیاز را نصب و اضافه می کنیم\n",
        " </p>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "kWmo43tDSV5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install transformers\n",
        "%pip install keras\n",
        "%pip install scikit_learn\n",
        "%pip install seqeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJZszmwt7ix8",
        "outputId": "527c0a42-6450-4cca-fffc-eff72822fdf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (2.11.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit_learn in /usr/local/lib/python3.8/dist-packages (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit_learn) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit_learn) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit_learn) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit_learn) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.8/dist-packages (1.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/dist-packages (from seqeval) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from seqeval) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install keras_preprocessing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-pxoXMCtLhI",
        "outputId": "478bb7ea-c896-4032-8bd3-6f76c75696d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras_preprocessing in /usr/local/lib/python3.8/dist-packages (1.1.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from keras_preprocessing) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.8/dist-packages (from keras_preprocessing) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnbr_pDcse3j"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "from transformers import BertForTokenClassification, AdamW\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm, trange\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertConfig, BertModel\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import joblib\n",
        "from seqeval.metrics import f1_score,recall_score,precision_score, accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load & Pre Process Data"
      ],
      "metadata": {
        "id": "FgxJ4PhRBc2J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<div dir = \"rtl\" style = 'font-family: \"B Zar\";'>\n",
        "  <p>در این بخش ابتدا ما از داده های خام نظرات فیلم دیتا فریم میسازیم و سعی در پیش پردازش داده ها کردیم سپس بعد از ساختن دیتا فریم بخش مربوطه را کامنت کردیم و فایل های csv نهایی را به پیوست اورده ایم. </p>\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "9zUltnpuoLX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# uncommet for create dataframe from raw data\n",
        "# columns = [\"sentence_id\" , \"word\" , \"tag\"]\n",
        "# data = pd.DataFrame([], columns=columns)\n",
        "\n",
        "# file1 = open('/content/engtest.bio', 'r')\n",
        "# Lines = file1.readlines()\n",
        "  \n",
        "# count = 1\n",
        "# for line in Lines:\n",
        "\n",
        "#     if(len((line.strip()).split('\\t')) == 1):\n",
        "#       count += 1\n",
        "#       print()\n",
        "#     else:\n",
        "#       data = data.append({'sentence_id':count,'word':(line.strip()).split('\\t')[1],'tag':(line.strip()).split('\\t')[0]}, ignore_index = True)\n",
        "# file1.close()\n",
        "# file2 = open('/content/trivia10k13test.bio', 'r')\n",
        "# Lines = file2.readlines()\n",
        "  \n",
        "# for line in Lines:\n",
        "\n",
        "#     if(len((line.strip()).split('\\t')) == 1):\n",
        "#       count += 1\n",
        "#     else:\n",
        "#       data = data.append({'sentence_id':count,'word':(line.strip()).split('\\t')[1],'tag':(line.strip()).split('\\t')[0]}, ignore_index = True)\n",
        "# file2.close()\n"
      ],
      "metadata": {
        "id": "vsMm8wTAN0-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# uncommet for create dataframe from raw data\n",
        "\n",
        "# data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "uv-N0EhgUvco",
        "outputId": "55c39490-89f6-4c2d-e859-25807b4cfb6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      sentence_id      word       tag\n",
              "0               1       are         O\n",
              "1               1     there         O\n",
              "2               1       any         O\n",
              "3               1      good         O\n",
              "4               1  romantic   B-GENRE\n",
              "...           ...       ...       ...\n",
              "63716        4396       the  I-Origin\n",
              "63717        4396     novel  I-Origin\n",
              "63718        4396        by  I-Origin\n",
              "63719        4396       ben  I-Origin\n",
              "63720        4396  sherwood  I-Origin\n",
              "\n",
              "[63721 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-763bc0dd-b45e-454f-9670-64148a4b0760\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_id</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>are</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>there</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>any</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>good</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>romantic</td>\n",
              "      <td>B-GENRE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63716</th>\n",
              "      <td>4396</td>\n",
              "      <td>the</td>\n",
              "      <td>I-Origin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63717</th>\n",
              "      <td>4396</td>\n",
              "      <td>novel</td>\n",
              "      <td>I-Origin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63718</th>\n",
              "      <td>4396</td>\n",
              "      <td>by</td>\n",
              "      <td>I-Origin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63719</th>\n",
              "      <td>4396</td>\n",
              "      <td>ben</td>\n",
              "      <td>I-Origin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63720</th>\n",
              "      <td>4396</td>\n",
              "      <td>sherwood</td>\n",
              "      <td>I-Origin</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>63721 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-763bc0dd-b45e-454f-9670-64148a4b0760')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-763bc0dd-b45e-454f-9670-64148a4b0760 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-763bc0dd-b45e-454f-9670-64148a4b0760');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# uncommet for create dataframe from raw data\n",
        "\n",
        "# pd.DataFrame(data).to_csv(\"/content/imdb_test.csv\")"
      ],
      "metadata": {
        "id": "FzeGK0nscKCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# uncommet for create dataframe from raw data\n",
        "\n",
        "# data = pd.read_csv(\"/content/imdb_test.csv\")\n",
        "# for i in range(len(data['tag'])):\n",
        "#   data['tag'].iloc[i] = data['tag'].iloc[i].upper()\n",
        "# pd.DataFrame(data).to_csv(\"/content/imdb_test2.csv\")"
      ],
      "metadata": {
        "id": "gWknnWPDuXax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<div dir = \"rtl\" style = 'font-family: \"B Zar\";'>\n",
        "  <p>سپس از روی دیتا فریم سعی کردیم زوج لیست ، جملات و تگ هر کلمعه را پیدا کنیم سپس کلمات جملات را با توکنایزر برت انکود کردیم و سپس به طولی واحد برای ورودی دادن به ترنسفرمر برده ایم. سپس با ایجاد 40 کلاس از تمامی کلاس هایی که این دیتا ست برای موجودیت های نامدار داشت سعی کرده ایم تگ بزنیم به هر کلمه سپس یک ماسک اتنشن نیز تعریف کرده ایم تا کلمات حاشیه را مدل برت متوجه نشود و با تگ PAD مشخص شده اند. </p>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "a0czrsvIWHWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/imdb_training2.csv\", encoding=\"latin1\", skip_blank_lines=False).fillna(method=\"ffill\")"
      ],
      "metadata": {
        "id": "PYTmsj2A7n7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(object):\n",
        "\n",
        "    def __init__(self, data):\n",
        "        self.counter = 1\n",
        "        self.data = data\n",
        "        agg_func = lambda s: [(word, tag) for word, tag in zip(s[\"word\"].values.tolist(),s[\"tag\"].values.tolist())]\n",
        "        self.grouped = self.data.groupby(\"sentence_id\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "\n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.counter)]\n",
        "            self.counter += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None"
      ],
      "metadata": {
        "id": "4oKxf7K4bbyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Dataset(data)\n",
        "sentences = [[word[0] for word in sentence] for sentence in dataset.sentences]\n",
        "print(sentences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBbA-DUdbfeh",
        "outputId": "5a7183dd-6713-4f74-be15-58faafd866d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['what', 'movies', 'star', 'bruce', 'willis']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tags = [[s[1] for s in sentence] for sentence in dataset.sentences]\n",
        "print(tags[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1Ph67TSbhFY",
        "outputId": "76f9a053-d5e1-4df7-880d-b7b220555a6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['O', 'O', 'O', 'B-ACTOR', 'I-ACTOR']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tag_values = list(set(data[\"tag\"].values))\n",
        "tag_values.append(\"PAD\")\n",
        "tag_values.sort()\n",
        "print(tag_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgNFdkBUbhMn",
        "outputId": "8bbdac16-6a8e-4775-d14a-23f463a04f01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['B-ACTOR', 'B-AWARD', 'B-CHARACTER', 'B-CHARACTER_NAME', 'B-DIRECTOR', 'B-GENRE', 'B-OPINION', 'B-ORIGIN', 'B-PLOT', 'B-QUOTE', 'B-RATING', 'B-RATINGS_AVERAGE', 'B-RELATIONSHIP', 'B-REVIEW', 'B-SONG', 'B-SOUNDTRACK', 'B-TITLE', 'B-TRAILER', 'B-YEAR', 'I-ACTOR', 'I-AWARD', 'I-CHARACTER', 'I-CHARACTER_NAME', 'I-DIRECTOR', 'I-GENRE', 'I-OPINION', 'I-ORIGIN', 'I-PLOT', 'I-QUOTE', 'I-RATING', 'I-RATINGS_AVERAGE', 'I-RELATIONSHIP', 'I-REVIEW', 'I-SONG', 'I-SOUNDTRACK', 'I-TITLE', 'I-TRAILER', 'I-YEAR', 'O', 'PAD']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tag2idx = {t: i for i, t in enumerate(tag_values)}\n",
        "print(tag2idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnugZlp9bhSA",
        "outputId": "d30e5b79-c3f5-432e-fb6e-ce31111f6723"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'B-ACTOR': 0, 'B-AWARD': 1, 'B-CHARACTER': 2, 'B-CHARACTER_NAME': 3, 'B-DIRECTOR': 4, 'B-GENRE': 5, 'B-OPINION': 6, 'B-ORIGIN': 7, 'B-PLOT': 8, 'B-QUOTE': 9, 'B-RATING': 10, 'B-RATINGS_AVERAGE': 11, 'B-RELATIONSHIP': 12, 'B-REVIEW': 13, 'B-SONG': 14, 'B-SOUNDTRACK': 15, 'B-TITLE': 16, 'B-TRAILER': 17, 'B-YEAR': 18, 'I-ACTOR': 19, 'I-AWARD': 20, 'I-CHARACTER': 21, 'I-CHARACTER_NAME': 22, 'I-DIRECTOR': 23, 'I-GENRE': 24, 'I-OPINION': 25, 'I-ORIGIN': 26, 'I-PLOT': 27, 'I-QUOTE': 28, 'I-RATING': 29, 'I-RATINGS_AVERAGE': 30, 'I-RELATIONSHIP': 31, 'I-REVIEW': 32, 'I-SONG': 33, 'I-SOUNDTRACK': 34, 'I-TITLE': 35, 'I-TRAILER': 36, 'I-YEAR': 37, 'O': 38, 'PAD': 39}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LEN = 75\n",
        "batch_size = 200\n",
        "epoch = 4\n",
        "max_grad_norm = 1.0\n",
        "device = torch.device(\"cuda\")\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)"
      ],
      "metadata": {
        "id": "ACID43f-bhVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizing_sentence(sentence, tag):\n",
        "    tokenized_sentence = []\n",
        "    tags = []\n",
        "\n",
        "    for word, tag in zip(sentence, tag):\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "        tags.extend([tag] * n_subwords)\n",
        "\n",
        "    return tokenized_sentence, tags"
      ],
      "metadata": {
        "id": "EHla2OY9eh9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentencse_tags = [\n",
        "    tokenizing_sentence(sent, tags)\n",
        "    for sent, tags in zip(sentences, tags)\n",
        "]"
      ],
      "metadata": {
        "id": "fy2p1WwZexzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentencse_tags[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZi8gmt6fLXg",
        "outputId": "ea551522-56f7-4f50-bfe0-3673830280cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['what', 'movies', 'star', 'br', '##uce', 'will', '##is'],\n",
              " ['O', 'O', 'O', 'B-ACTOR', 'B-ACTOR', 'I-ACTOR', 'I-ACTOR'])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sentencse_tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lffzZ0rszdDi",
        "outputId": "6758ca8f-040b-46cf-9175-7eb93c5814ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17591"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_texts = [token_tag_pair[0] for token_tag_pair in sentencse_tags]"
      ],
      "metadata": {
        "id": "YYLHcg0eeyyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_texts[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRd0RoCIffq4",
        "outputId": "3fc912aa-167b-4f7f-8a03-5998dcbf2566"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what', 'movies', 'star', 'br', '##uce', 'will', '##is']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tags = [token_tag_pair[1] for token_tag_pair in sentencse_tags]\n"
      ],
      "metadata": {
        "id": "RYYhIYreey3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tags[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k22xiHISfnN4",
        "outputId": "4363f81c-db9d-4a4c-fabc-bc9da5d6add0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'O', 'O', 'B-ACTOR', 'B-ACTOR', 'I-ACTOR', 'I-ACTOR']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in all_texts],maxlen=LEN, dtype=\"long\", value=0.0,truncating=\"post\", padding=\"post\")"
      ],
      "metadata": {
        "id": "RV5_Ue7ley73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSACpCHMgmK4",
        "outputId": "50f148b1-25d4-4979-9fb4-718807a6de14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1184,  5558,  2851,  9304, 15776,  1209,  1548,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tags = pad_sequences([[tag2idx.get(l) for l in tagi] for tagi in tags],maxlen=LEN, value=tag2idx[\"PAD\"], padding=\"post\",dtype=\"long\", truncating=\"post\")"
      ],
      "metadata": {
        "id": "3aAWecbZey_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tags[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHR6fKNPg34N",
        "outputId": "1708c129-5f9c-467e-8c41-657ecbf035e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([38, 38, 38,  0,  0, 19, 19, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,\n",
              "       39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,\n",
              "       39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,\n",
              "       39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,\n",
              "       39, 39, 39, 39, 39, 39, 39])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_masks = [[float(k != 0.0) for k in i] for i in input_ids]"
      ],
      "metadata": {
        "id": "eSpGeEXfe6u3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_masks[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyJbVDAEhGXC",
        "outputId": "784c6bff-0686-4612-ce52-2d75e605cc6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_inputs, val_inputs, train_tags, val_tags = train_test_split(input_ids, tags,test_size=0.2)\n",
        "train_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids,test_size=0.2)"
      ],
      "metadata": {
        "id": "kO-xdN9UhadS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_inputs = torch.tensor(train_inputs)\n",
        "val_inputs = torch.tensor(val_inputs)\n",
        "train_tags = torch.tensor(train_tags)\n",
        "val_tags = torch.tensor(val_tags)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "val_masks = torch.tensor(val_masks)\n"
      ],
      "metadata": {
        "id": "e_Qwfw8SiXAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train1 = TensorDataset(train_inputs, train_masks, train_tags)\n",
        "train2 = RandomSampler(train1)\n",
        "train_batches = DataLoader(train1, sampler=train2, batch_size=batch_size)\n",
        "valid1 = TensorDataset(val_inputs, val_masks, val_tags)\n",
        "valid2 = SequentialSampler(valid1)\n",
        "eval_batches = DataLoader(valid1, sampler=valid2, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "0qSBosKUiY5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<div dir = \"rtl\" style = 'font-family: \"B Zar\";'>\n",
        "  <p>و در نهایت هر 3 این داده ها در قالب یه داده به مدل برت به عنوان ورودی داده میشود.</p>\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "u6dtuRYvWOLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train1[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6CqiaQliceP",
        "outputId": "6373a768-0a7a-4950-d558-a1c01cf1332f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 1184,  1108,  1115, 22572, 11657,  1158, 27629,  8928,  2523,  1187,\n",
              "          1119,  1307,   170,  5176,  1133,  1136,  1126,  2168,  2523,   170,\n",
              "          6376,  2523,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0]),\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0.]),\n",
              " tensor([38, 38, 38,  0,  0,  0, 19, 19, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38,\n",
              "         38, 38,  5, 38, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,\n",
              "         39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,\n",
              "         39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,\n",
              "         39, 39, 39]))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bert Model"
      ],
      "metadata": {
        "id": "AklA565TGHfb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<div dir = \"rtl\" style = 'font-family: \"B Zar\";'>\n",
        "  <p>در این مرحله مدل برت بر روی دادگان ما به تفکیک 80 به 20 داده اموزش و ارزیابی تقسیم میشود و اموزش میبیبند. و در هر مرحله 4 معیار گفته شده را برای داده ها گزارش میکینم </p>\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "ElkBUpeUWT1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForTokenClassification.from_pretrained(\"bert-base-cased\",num_labels=len(tag2idx),output_attentions = False,output_hidden_states = False)\n",
        "model.cuda();\n",
        "param_optimizer = list(model.classifier.named_parameters())\n",
        "optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "optimizer = AdamW(optimizer_grouped_parameters,lr=1e-1,eps=1e-8)\n",
        "steps = len(train_batches) * epoch\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps=0,num_training_steps=steps)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AU1G7LaojE-m",
        "outputId": "310df0ad-4b01-4eed-f41c-7ef7364ec4db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_values, eval_loss_values = [], []\n",
        "\n",
        "for i in range(epoch):\n",
        "    print(\"_\"*100)\n",
        "    print(f\"epoch={i+1}\")\n",
        "    ## train ##\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for step, batch in enumerate(train_batches):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        model.zero_grad()\n",
        "        outputs = model(b_input_ids, token_type_ids=None,attention_mask=b_input_mask, labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        loss.backward()\n",
        "        total_loss += loss.item()\n",
        "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_batches)\n",
        "    loss_values.append(avg_train_loss)\n",
        "    print(f\"train_loss={avg_train_loss}\")\n",
        "    \n",
        "    ## test ##\n",
        "    model.eval()\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    predictions , true_labels = [], []\n",
        "    for batch in eval_batches:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        with torch.no_grad():\n",
        "            outputs = model(b_input_ids, token_type_ids=None,\n",
        "                            attention_mask=b_input_mask, labels=b_labels)\n",
        "        logits = outputs[1].detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        eval_loss += outputs[0].mean().item()\n",
        "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "        true_labels.extend(label_ids)\n",
        "\n",
        "    eval_loss = eval_loss / len(eval_batches)\n",
        "    eval_loss_values.append(eval_loss)\n",
        "    print(f\"test_loss={eval_loss}\")\n",
        "\n",
        "    pred_tags = [tag_values[p_i] for p, l in zip(predictions, true_labels)\n",
        "                                 for p_i, l_i in zip(p, l) if tag_values[l_i] != \"PAD\"]\n",
        "    valid_tags = [tag_values[l_i] for l in true_labels\n",
        "                                  for l_i in l if tag_values[l_i] != \"PAD\"]\n",
        "\n",
        "    print(f\"Test Accuracy: {accuracy_score(pred_tags, valid_tags)*100} %\")\n",
        "    \n",
        "    print(\"Test precision_score: {}\".format(precision_score([pred_tags], [valid_tags])))\n",
        "    print(\"Test recall_score: {}\".format(recall_score([pred_tags], [valid_tags])))\n",
        "    print(\"Test F1-Score: {}\".format(f1_score([pred_tags], [valid_tags] , average='macro')))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnTy0d1XkXEw",
        "outputId": "26dce0cc-2363-40e7-9c3c-9af1672bc19e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "____________________________________________________________________________________________________\n",
            "epoch=1\n",
            "train_loss=2.64115562489335\n",
            "test_loss=0.7187817527188195\n",
            "Test Accuracy: 59.08487014835669 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test precision_score: 0.366592809663355\n",
            "Test recall_score: 0.2117409074020559\n",
            "Test F1-Score: 0.17088046415696248\n",
            "____________________________________________________________________________________________________\n",
            "epoch=2\n",
            "train_loss=0.5830689861740864\n",
            "test_loss=0.43197541766696507\n",
            "Test Accuracy: 61.06823142378136 %\n",
            "Test precision_score: 0.36923736687870773\n",
            "Test recall_score: 0.2675436325029779\n",
            "Test F1-Score: 0.23127670561587377\n",
            "____________________________________________________________________________________________________\n",
            "epoch=3\n",
            "train_loss=0.42141887839411346\n",
            "test_loss=0.32379403875933754\n",
            "Test Accuracy: 67.00724385537595 %\n",
            "Test precision_score: 0.42434422128511184\n",
            "Test recall_score: 0.29534374689085663\n",
            "Test F1-Score: 0.24430994876527684\n",
            "____________________________________________________________________________________________________\n",
            "epoch=4\n",
            "train_loss=0.3580798754389857\n",
            "test_loss=0.287511155837112\n",
            "Test Accuracy: 69.25790023091766 %\n",
            "Test precision_score: 0.4559359588306769\n",
            "Test recall_score: 0.33158332466992413\n",
            "Test F1-Score: 0.2921223679462492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Model"
      ],
      "metadata": {
        "id": "syQNMEd7GSmV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<div dir = \"rtl\" style = 'font-family: \"B Zar\";'>\n",
        "  <p>در نهایت مدل را میتوانیم با این دستورات سیو کنیم </p>\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "2uplBBPOWZjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'ner_bert_model.sav'\n",
        "joblib.dump(model, filename)"
      ],
      "metadata": {
        "id": "lMJ7gtHQmEAL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2b9f3cc-7ac8-4106-c53c-faa47dffa2fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ner_bert_model.sav']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Model"
      ],
      "metadata": {
        "id": "byHIQP66GVgk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<div dir = \"rtl\" style = 'font-family: \"B Zar\";'>\n",
        "  <p>سپس با گرفتن کوئری میتوان خروجی مدل آموزش دیدمان را بر روی این جمله مشاهده کنیم که به هر کلمه چه موجودیت نامداری اختصاص میدهد. که میبیینم مدل دقت خیلی بالایی ندارد به علت دشوار بودن تسک و همچنین محدودیت سخت افزاری برای ترین با زمان های زیاد بر روی دادگان که حجم بسیار بالایی نیز داشتند که البته در صورت سوال نیز خواسته به دقت بهینه رسیدن نیز نبود و مراحل پیاده سازی ذکر شده بود اولویت دارد\n",
        "\n",
        "</p>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "jfDtVpLoWfNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Professor gave justice to his role. What a legend. you'll start admiring some characters. Who thought a TV series on a money heist will be so interesting.\""
      ],
      "metadata": {
        "id": "46Yn6moBUA-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenized_query = tokenizer.encode(query)\n",
        "model_query = torch.tensor([tokenized_query]).cuda()\n",
        "with torch.no_grad():\n",
        "    output = model(model_query)\n",
        "label_indices = np.argmax(output[0].to('cpu').numpy(), axis=2)\n",
        "tokens = tokenizer.convert_ids_to_tokens(model_query.to('cpu').numpy()[0])\n",
        "new_tokens, new_tags = [], []\n",
        "for token, label_idx in zip(tokens, label_indices[0]):\n",
        "    if token.startswith(\"##\"):\n",
        "        new_tokens[-1] = new_tokens[-1] + token[2:]\n",
        "    else:\n",
        "        new_tags.append(tag_values[label_idx])\n",
        "        new_tokens.append(token)"
      ],
      "metadata": {
        "id": "dIKD7PixxjAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token, label in zip(new_tokens, new_tags):\n",
        "    print(f\"{label}\\t{token}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CcOATJuUFHa",
        "outputId": "eff98368-da4b-4559-a0ed-595d361d7a59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O\t[CLS]\n",
            "O\tProfessor\n",
            "O\tgave\n",
            "B-REVIEW\tjustice\n",
            "O\tto\n",
            "O\this\n",
            "O\trole\n",
            "O\t.\n",
            "O\tWhat\n",
            "O\ta\n",
            "B-GENRE\tlegend\n",
            "O\t.\n",
            "B-QUOTE\tyou\n",
            "O\t'\n",
            "I-QUOTE\tll\n",
            "O\tstart\n",
            "I-OPINION\tadmiring\n",
            "O\tsome\n",
            "I-PLOT\tcharacters\n",
            "O\t.\n",
            "O\tWho\n",
            "O\tthought\n",
            "O\ta\n",
            "O\tTV\n",
            "I-GENRE\tseries\n",
            "I-PLOT\ton\n",
            "I-PLOT\ta\n",
            "I-PLOT\tmoney\n",
            "I-PLOT\theist\n",
            "O\twill\n",
            "O\tbe\n",
            "O\tso\n",
            "B-GENRE\tinteresting\n",
            "PAD\t.\n",
            "PAD\t[SEP]\n"
          ]
        }
      ]
    }
  ]
}